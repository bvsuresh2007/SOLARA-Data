version: "3.9"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: solara_backend
    restart: unless-stopped
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL:-}
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN:-}
      SLACK_CHANNEL_ID: ${SLACK_CHANNEL_ID:-}
      API_SECRET_KEY: ${API_SECRET_KEY:-change-me-in-production}
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: solara_frontend
    restart: unless-stopped
    depends_on:
      - backend
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:8000}
    ports:
      - "3000:3000"

  scrapers:
    build:
      context: ./scrapers
      dockerfile: Dockerfile
    container_name: solara_scrapers
    restart: unless-stopped
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      SWIGGY_EMAIL: ${SWIGGY_EMAIL:-}
      SWIGGY_PASSWORD: ${SWIGGY_PASSWORD:-}
      BLINKIT_EMAIL: ${BLINKIT_EMAIL:-}
      BLINKIT_PASSWORD: ${BLINKIT_PASSWORD:-}
      AMAZON_EMAIL: ${AMAZON_EMAIL:-}
      AMAZON_PASSWORD: ${AMAZON_PASSWORD:-}
      ZEPTO_EMAIL: ${ZEPTO_EMAIL:-}
      ZEPTO_PASSWORD: ${ZEPTO_PASSWORD:-}
      SHOPIFY_API_KEY: ${SHOPIFY_API_KEY:-}
      SHOPIFY_API_SECRET: ${SHOPIFY_API_SECRET:-}
      SHOPIFY_STORE_URL: ${SHOPIFY_STORE_URL:-}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL:-}
      TZ: Asia/Kolkata
      SCRAPE_SCHEDULE_HOUR: ${SCRAPE_SCHEDULE_HOUR:-11}
      SCRAPE_SCHEDULE_MINUTE: ${SCRAPE_SCHEDULE_MINUTE:-0}
      RAW_DATA_PATH: /app/data/raw
      PROCESSED_DATA_PATH: /app/data/processed
    volumes:
      - ./data:/app/data

